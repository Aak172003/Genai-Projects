{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U -q \"google-genai>=0.7.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY : : :  AIzaSyDPSsYK-Cpyp4mzQyN-4Cf5f7cKesH9yCI\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv  # helps to load env files\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "print(\"GOOGLE_API_KEY : : : \", GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_light():\n",
    "    \"\"\"Turn on the lighting system\"\"\"\n",
    "    print(\"LIGHTBOT : Lights Enabled\")\n",
    "\n",
    "def set_light_color(rgb_hex:str):\n",
    "    \"\"\"Set the light color . List must be enabled for this tow work\"\"\"\n",
    "    print(f\"LIGHTBOT : Lights set to {rgb_hex}.\")\n",
    "\n",
    "\n",
    "def stop_light():\n",
    "    \"\"\"stop flashing light\"\"\"\n",
    "    print(f\"LIGHTBOT : Lights turned off .\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<function __main__.enable_light()>,\n",
       "  <function __main__.set_light_color(rgb_hex: str)>,\n",
       "  <function __main__.stop_light()>],\n",
       " genai.GenerativeModel(\n",
       "     model_name='models/gemini-2.0-flash',\n",
       "     generation_config={},\n",
       "     safety_settings={},\n",
       "     tools=<google.generativeai.types.content_types.FunctionLibrary object at 0x000002380AB09D00>,\n",
       "     system_instruction='You are a helpful lighting system bot. You can trun lights on and off ,\\n                 and you can set the light color . Do not perform any other task',\n",
       "     cached_content=None\n",
       " ),\n",
       " ChatSession(\n",
       "     model=genai.GenerativeModel(\n",
       "         model_name='models/gemini-2.0-flash',\n",
       "         generation_config={},\n",
       "         safety_settings={},\n",
       "         tools=<google.generativeai.types.content_types.FunctionLibrary object at 0x000002380AB09D00>,\n",
       "         system_instruction='You are a helpful lighting system bot. You can trun lights on and off ,\\n                 and you can set the light color . Do not perform any other task',\n",
       "         cached_content=None\n",
       "     ),\n",
       "     history=[]\n",
       " ),\n",
       " [function_declarations {\n",
       "    name: \"enable_light\"\n",
       "    description: \"Turn on the lighting system\"\n",
       "  }\n",
       "  function_declarations {\n",
       "    name: \"set_light_color\"\n",
       "    description: \"Set the light color . List must be enabled for this tow work\"\n",
       "    parameters {\n",
       "      type_: OBJECT\n",
       "      properties {\n",
       "        key: \"rgb_hex\"\n",
       "        value {\n",
       "          type_: STRING\n",
       "        }\n",
       "      }\n",
       "      required: \"rgb_hex\"\n",
       "    }\n",
       "  }\n",
       "  function_declarations {\n",
       "    name: \"stop_light\"\n",
       "    description: \"stop flashing light\"\n",
       "  }])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "light_controls = [enable_light , set_light_color , stop_light]\n",
    "\n",
    "# Set persona here \n",
    "instruction = \"\"\"You are a helpful lighting system bot. You can trun lights on and off ,\n",
    "                 and you can set the light color . Do not perform any other task\"\"\"\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    \"gemini-2.0-flash\", \n",
    "    tools=light_controls , \n",
    "    system_instruction=instruction\n",
    ")\n",
    "\n",
    "chat = model.start_chat()\n",
    "\n",
    "# This tells us no of tools assigned to particular model\n",
    "light_controls , model , chat , model._tools.to_proto()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create helper function for setting function_calling_config on tool_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.generativeai.types import content_types\n",
    "from collections.abc import Iterable\n",
    "\n",
    "# mode can be of 3 types \n",
    " \n",
    "# any -> \n",
    "\n",
    "def tool_config_from_mode(mode:str , fns:Iterable[str] = ()):\n",
    "    \"\"\"\"Create a tool config with the specified function calling mode \"\"\",\n",
    "    return content_types.to_tool_config(\n",
    "        {\"function_calling_config\":{\"mode\":mode , \"allowed_function_names\":fns}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### None : If you have provided the model with tools, but don't want to use those tools for the current converstional turn, then specify none as the mode . \n",
    "### None : Nones tells the model not to make any function calls \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_config = tool_config_from_mode(\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"Hello! I can turn lights on and off, and I can set the light color. How can I help you today?\\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"avg_logprobs\": -0.14205483289865348\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 40,\n",
       "        \"candidates_token_count\": 26,\n",
       "        \"total_token_count\": 66\n",
       "      },\n",
       "      \"model_version\": \"gemini-2.0-flash\"\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.send_message(\"Hello light bot , what can you do\", tool_config=tool_config)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### auto : To allows the model to decide whether to respond in text or call specific function, you can specify auto as the mode \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function_call {\n",
       "  name: \"enable_light\"\n",
       "  args {\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_config = tool_config_from_mode(\"auto\")\n",
    "\n",
    "tool_config\n",
    "\n",
    "response = chat.send_message(\"light this place up \", tool_config=tool_config)\n",
    "\n",
    "response.parts[0]\n",
    "\n",
    "# you are not actually calling the function , so remove this from the history .\n",
    "# chat.rewind()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any : Setting the mode to ANY will force the model to make a function call . By setting allowed_functions_name , the model will only choose from these functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[function_call {\n",
       "  name: \"set_light_color\"\n",
       "  args {\n",
       "    fields {\n",
       "      key: \"rgb_hex\"\n",
       "      value {\n",
       "        string_value: \"800080\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", function_call {\n",
       "  name: \"enable_light\"\n",
       "  args {\n",
       "  }\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_fns = ['set_light_color', 'enable_light']\n",
    "\n",
    "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
    "\n",
    "response = chat.send_message(\"make this place purple and light this place up as well \", tool_config=tool_config)\n",
    "\n",
    "response.parts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Function Calling\n",
    "\n",
    "#### any : enable_automatic_function_calling only available in \"any\" case but there is 2 difference i don't enable this as enable_automatic_function_calling true , so it just show which function have  , But if enable as true so it can call those function as per given prompt . \n",
    "\n",
    "##### Our Agentic Ai will decide own itself what function need to be execute based on given prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIGHTBOT : Lights set to 800080.\n",
      "LIGHTBOT : Lights Enabled\n"
     ]
    }
   ],
   "source": [
    "available_fns = ['set_light_color', 'enable_light']\n",
    "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
    "\n",
    "auto_chat = model.start_chat(enable_automatic_function_calling=True)\n",
    "response = auto_chat.send_message(\"make this place purple and light this place up as well\", tool_config=tool_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have set the light color to purple and enabled the lighting system.\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.parts[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIGHTBOT : Lights Enabled\n",
      "LIGHTBOT : Lights set to FFA500.\n",
      "LIGHTBOT : Lights turned off .\n"
     ]
    }
   ],
   "source": [
    "available_fns = ['set_light_color', 'enable_light' , 'stop_light']\n",
    "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
    "\n",
    "\n",
    "auto_chat = model.start_chat(enable_automatic_function_calling=True)\n",
    "response = auto_chat.send_message(\"Here is dark in my surrounding please up the light and make it orange color then, switch off the light \", tool_config=tool_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OK, I've turned on the light and set it to orange. After that, I've switched off the light.\\n\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.parts[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel function calling\n",
    "##### In addition to basic function calling described above, you can also call multiple functions in a single turn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIGHTBOT : Lights set to 0000FF.\n",
      "LIGHTBOT : Lights turned off .\n"
     ]
    }
   ],
   "source": [
    "available_fns = ['set_light_color', 'enable_light' , 'stop_light']\n",
    "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
    "\n",
    "\n",
    "auto_chat = model.start_chat(enable_automatic_function_calling=True)\n",
    "response = auto_chat.send_message(\"It's awful dark in here - make it blue color and then switch off the light\", tool_config=tool_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OK. I've set the light to blue and switched it off.\\n\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.parts[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIGHTBOT : Lights turned off .\n"
     ]
    }
   ],
   "source": [
    "available_fns = ['set_light_color', 'enable_light' , 'stop_light']\n",
    "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
    "\n",
    "\n",
    "auto_chat = model.start_chat(enable_automatic_function_calling=True)\n",
    "response = auto_chat.send_message(\"switch off the light\", tool_config=tool_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Automatic tool calling on another example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_light_values(brightness: int, color_temp: str) -> dict[str, int | str]:\n",
    "    \"\"\"Set the brightness and color temperature of a room light. (mock API).\n",
    "\n",
    "    Args:\n",
    "        brightness: Light level from 0 to 100. Zero is off and 100 is full brightness\n",
    "        color_temp: Color temperature of the light fixture, which can be `daylight`, `cool` or `warm`.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the set brightness and color temperature.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"brightness\": brightness,\n",
    "        \"colorTemperature\": color_temp\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genai.GenerativeModel(\n",
       "    model_name='models/gemini-2.0-flash',\n",
       "    generation_config={},\n",
       "    safety_settings={},\n",
       "    tools=<google.generativeai.types.content_types.FunctionLibrary object at 0x000002380AB0B240>,\n",
       "    system_instruction=None,\n",
       "    cached_content=None\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name=\"gemini-2.0-flash\", tools=[set_light_values])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I can help with that! I can dim the lights, start some music, and even turn on the disco ball. How would you like the music? Energetic or not? And loud or not?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat = model.start_chat(enable_automatic_function_calling=True)\n",
    "\n",
    "\n",
    "response = chat.send_message('please make it feel romentic . so i can comence with my couple ?')\n",
    "print(response.parts[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel function calling\n",
    "##### In addition to basic function calling described above, you can also call multiple functions in a single turn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_disco_ball(power: bool) -> bool:\n",
    "    \"\"\"Powers the spinning disco ball.\"\"\"\n",
    "    print(f\"Disco ball is {'spinning!' if power else 'stopped.'}\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def start_music(energetic: bool, loud: bool) -> str:\n",
    "    \"\"\"Play some music matching the specified parameters.\n",
    "\n",
    "    Args:\n",
    "      energetic: Whether the music is energetic or not.\n",
    "      loud: Whether the music is loud or not.\n",
    "\n",
    "    Returns: The name of the song being played.\n",
    "    \"\"\"\n",
    "    print(f\"Starting music! {energetic=} {loud=}\")\n",
    "    return \"Never gonna give you up.\"\n",
    "\n",
    "\n",
    "def dim_lights(brightness: float) -> bool:\n",
    "    \"\"\"Dim the lights.\n",
    "\n",
    "    Args:\n",
    "      brightness: The brightness of the lights, 0.0 is off, 1.0 is full.\n",
    "    \"\"\"\n",
    "    print(f\"Lights are now set to {brightness:.0%}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "power_disco_ball(power=True)\n",
      "start_music(loud=True, energetic=True)\n",
      "dim_lights(brightness=0.5)\n"
     ]
    }
   ],
   "source": [
    "# Set the model up with tools.\n",
    "house_fns = [power_disco_ball, start_music, dim_lights]\n",
    "\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-2.0-flash\" , tools=house_fns)\n",
    "\n",
    "# Call the API.\n",
    "chat = model.start_chat()\n",
    "response = chat.send_message('Turn this place into a party night!')\n",
    "\n",
    "# Print out each of the function calls requested from this single call.\n",
    "for part in response.parts:\n",
    "  if fn := part.function_call:\n",
    "    args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n",
    "    print(f\"{fn.name}({args})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_lights(brightness=0.1)\n",
      "start_music(loud=False, energetic=False)\n",
      "power_disco_ball(power=False)\n"
     ]
    }
   ],
   "source": [
    "# Call the API.\n",
    "chat = model.start_chat()\n",
    "response = chat.send_message('Turn this place into sleepy night!')\n",
    "\n",
    "# Print out each of the function calls requested from this single call.\n",
    "for part in response.parts:\n",
    "  if fn := part.function_call:\n",
    "    args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n",
    "    print(f\"{fn.name}({args})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[function_declarations {\n",
       "   name: \"power_disco_ball\"\n",
       "   description: \"Powers the spinning disco ball.\"\n",
       "   parameters {\n",
       "     type_: OBJECT\n",
       "     properties {\n",
       "       key: \"power\"\n",
       "       value {\n",
       "         type_: BOOLEAN\n",
       "       }\n",
       "     }\n",
       "     required: \"power\"\n",
       "   }\n",
       " }\n",
       " function_declarations {\n",
       "   name: \"start_music\"\n",
       "   description: \"Play some music matching the specified parameters.\\n\\nArgs:\\n  energetic: Whether the music is energetic or not.\\n  loud: Whether the music is loud or not.\\n\\nReturns: The name of the song being played.\\n\"\n",
       "   parameters {\n",
       "     type_: OBJECT\n",
       "     properties {\n",
       "       key: \"loud\"\n",
       "       value {\n",
       "         type_: BOOLEAN\n",
       "       }\n",
       "     }\n",
       "     properties {\n",
       "       key: \"energetic\"\n",
       "       value {\n",
       "         type_: BOOLEAN\n",
       "       }\n",
       "     }\n",
       "     required: \"energetic\"\n",
       "     required: \"loud\"\n",
       "   }\n",
       " }\n",
       " function_declarations {\n",
       "   name: \"dim_lights\"\n",
       "   description: \"Dim the lights.\\n\\nArgs:\\n  brightness: The brightness of the lights, 0.0 is off, 1.0 is full.\\n\"\n",
       "   parameters {\n",
       "     type_: OBJECT\n",
       "     properties {\n",
       "       key: \"brightness\"\n",
       "       value {\n",
       "         type_: NUMBER\n",
       "       }\n",
       "     }\n",
       "     required: \"brightness\"\n",
       "   }\n",
       " }]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This tells us no of tools assigned to particular model\n",
    "model._tools.to_proto()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
