{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U -q \"google-genai>=0.7.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv  # helps to load env files\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "print(\"GOOGLE_API_KEY : : : \", GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_light():\n",
    "    \"\"\"Turn on the lighting system\"\"\"\n",
    "    print(\"LIGHTBOT : Lights Enabled\")\n",
    "\n",
    "def set_light_color(rgb_hex:str):\n",
    "    \"\"\"Set the light color . List must be enabled for this tow work\"\"\"\n",
    "    print(f\"LIGHTBOT : Lights set to {rgb_hex}.\")\n",
    "\n",
    "\n",
    "def stop_light():\n",
    "    \"\"\"stop flashing light\"\"\"\n",
    "    print(f\"LIGHTBOT : Lights turned off .\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "light_controls = [enable_light , set_light_color , stop_light]\n",
    "\n",
    "instruction = \"\"\"You are a helpful lighting system bot. You can trun lights on and off ,\n",
    "                 and you can set the light color . Do not perform any other task\"\"\"\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    \"gemini-2.0-flash\", \n",
    "    tools=light_controls , \n",
    "    system_instruction=instruction\n",
    ")\n",
    "\n",
    "chat = model.start_chat()\n",
    "\n",
    "# This tells us no of tools assigned to particular model\n",
    "light_controls , model , chat , model._tools.to_proto()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create helper function for setting function_calling_config on tool_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.generativeai.types import content_types\n",
    "from collections.abc import Iterable\n",
    "\n",
    "# mode can be of 3 types \n",
    "# none -> \n",
    "# auto -> \n",
    "# any -> \n",
    "\n",
    "def tool_config_from_mode(mode:str , fns:Iterable[str] = ()):\n",
    "    \"\"\"\"Create a tool config with the specified function calling mode \"\"\",\n",
    "    return content_types.to_tool_config(\n",
    "        {\"function_calling_config\":{\"mode\":mode , \"allowed_function_names\":fns}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_config = tool_config_from_mode(\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.send_message(\"Hello light bot , what can you do\", tool_config=tool_config)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_config = tool_config_from_mode(\"auto\")\n",
    "\n",
    "tool_config\n",
    "\n",
    "response = chat.send_message(\"light this place up \", tool_config=tool_config)\n",
    "\n",
    "response.parts[0]\n",
    "\n",
    "# you are not actually calling the function , so remove this from the history .\n",
    "# chat.rewind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_fns = ['set_light_color', 'enable_light']\n",
    "\n",
    "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
    "\n",
    "response = chat.send_message(\"make this place purple and light this place up as well \", tool_config=tool_config)\n",
    "\n",
    "response.parts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Function Calling\n",
    "\n",
    "##### Our Agentic Ai will decide own itself what funct need to be execute based on given prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_fns = ['set_light_color', 'enable_light']\n",
    "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
    "\n",
    "\n",
    "auto_chat = model.start_chat(enable_automatic_function_calling=True)\n",
    "response = auto_chat.send_message(\"make this place purple and light this place up as well\", tool_config=tool_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.parts[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_fns = ['set_light_color', 'enable_light' , 'stop_light']\n",
    "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
    "\n",
    "\n",
    "auto_chat = model.start_chat(enable_automatic_function_calling=True)\n",
    "response = auto_chat.send_message(\"It's awful dark in here - make it orange color\", tool_config=tool_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.parts[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel function calling\n",
    "##### In addition to basic function calling described above, you can also call multiple functions in a single turn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_fns = ['set_light_color', 'enable_light' , 'stop_light']\n",
    "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
    "\n",
    "\n",
    "auto_chat = model.start_chat(enable_automatic_function_calling=True)\n",
    "response = auto_chat.send_message(\"It's awful dark in here - make it blue color and then switch off the light\", tool_config=tool_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.parts[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_fns = ['set_light_color', 'enable_light' , 'stop_light']\n",
    "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
    "\n",
    "\n",
    "auto_chat = model.start_chat(enable_automatic_function_calling=True)\n",
    "response = auto_chat.send_message(\"switch off the light\", tool_config=tool_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Automatic tool calling on another example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_light_values(brightness: int, color_temp: str) -> dict[str, int | str]:\n",
    "    \"\"\"Set the brightness and color temperature of a room light. (mock API).\n",
    "\n",
    "    Args:\n",
    "        brightness: Light level from 0 to 100. Zero is off and 100 is full brightness\n",
    "        color_temp: Color temperature of the light fixture, which can be `daylight`, `cool` or `warm`.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the set brightness and color temperature.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"brightness\": brightness,\n",
    "        \"colorTemperature\": color_temp\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(model_name=\"gemini-2.0-flash\", tools=[set_light_values])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = model.start_chat(enable_automatic_function_calling=True)\n",
    "\n",
    "\n",
    "response = chat.send_message('Dim the light so the room feels cozy and warm')\n",
    "print(response.parts[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel function calling\n",
    "##### In addition to basic function calling described above, you can also call multiple functions in a single turn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_disco_ball(power: bool) -> bool:\n",
    "    \"\"\"Powers the spinning disco ball.\"\"\"\n",
    "    print(f\"Disco ball is {'spinning!' if power else 'stopped.'}\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def start_music(energetic: bool, loud: bool) -> str:\n",
    "    \"\"\"Play some music matching the specified parameters.\n",
    "\n",
    "    Args:\n",
    "      energetic: Whether the music is energetic or not.\n",
    "      loud: Whether the music is loud or not.\n",
    "\n",
    "    Returns: The name of the song being played.\n",
    "    \"\"\"\n",
    "    print(f\"Starting music! {energetic=} {loud=}\")\n",
    "    return \"Never gonna give you up.\"\n",
    "\n",
    "\n",
    "def dim_lights(brightness: float) -> bool:\n",
    "    \"\"\"Dim the lights.\n",
    "\n",
    "    Args:\n",
    "      brightness: The brightness of the lights, 0.0 is off, 1.0 is full.\n",
    "    \"\"\"\n",
    "    print(f\"Lights are now set to {brightness:.0%}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model up with tools.\n",
    "house_fns = [power_disco_ball, start_music, dim_lights]\n",
    "\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-2.0-flash\" , tools=house_fns)\n",
    "\n",
    "# Call the API.\n",
    "chat = model.start_chat()\n",
    "response = chat.send_message('Turn this place into a party night!')\n",
    "\n",
    "# Print out each of the function calls requested from this single call.\n",
    "for part in response.parts:\n",
    "  if fn := part.function_call:\n",
    "    args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n",
    "    print(f\"{fn.name}({args})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the API.\n",
    "chat = model.start_chat()\n",
    "response = chat.send_message('Turn this place into sleepy night!')\n",
    "\n",
    "# Print out each of the function calls requested from this single call.\n",
    "for part in response.parts:\n",
    "  if fn := part.function_call:\n",
    "    args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n",
    "    print(f\"{fn.name}({args})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells us no of tools assigned to particular model\n",
    "model._tools.to_proto()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
